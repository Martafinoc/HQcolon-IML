# TotalSegmentator Batch Processing Pipeline

This pipeline is designed to segment organs in 3D CT images stored on our ERDA drive using the TotalSegmentator tool. The following instructions outline the setup and execution process on our dataset, including how to handle input/output files and manage batch processing.

---

## Dataset and Directory Layout on ERDA

Our ERDA drive is mounted at `IRE-DATA` and structured as follows:

- **`IRE-DATA/CT/converted`**: Contains the preprocessed input images in `.mha.gz` format. These images are used as input for the segmentation process.
- **`IRE-DATA/CT/segmentations_totalsegmentator`**: Stores the output segmentation files generated by TotalSegmentator. Each input image will have a corresponding directory here with organ-specific segmentation files.

Each output file is named following a consistent format:
```
<input_name>_totalseg-<organ>.mha.gz
```
This naming convention allows easy data wrangling for specific organ segmentations. For example, if the input image is named `sub001_pos-supine_scan-1_conv-sitk.mha.gz`, a lung segmentation file will be named:
```
sub001_pos-supine_scan-1_conv-sitk_totalseg-lung.mha.gz
```

---

## Mounting ERDA

To ensure the pipeline has access to both input and output directories, mount the ERDA drive at the specified location:

1. **Mounting**:
   - Use the `mount_erda.sh` script to mount the ERDA drive.
   - Make sure the `key`, `user`, `erdadir`, and `mnt` variables are correctly set within `mount_erda.sh` to match our access credentials and directories.
   - I also had to create an SFTP password on https://erda.dk/wsgi-bin/setup.py?topic=sftp, and create a public/private key pair

   ```bash
   ./mount_erda.sh
   ```
   - This mounts the `IRE-DATA` directory, giving access to all folders under `CT`, including `converted` for inputs and `segmentations_totalsegmentator` for outputs.

2. **Unmounting**:
   - Once processing is complete, run:
   ```bash
   ./unmount_erda.sh
   ```

---

## Pipeline Steps

### Step 1: Prepare Image Paths

1. **Generate Image Paths**:
   - Run `create_image_paths.py` to create a list of paths to all images in `IRE-DATA/CT/converted`. This generates a text file, `image_paths.txt`, containing the absolute paths to each input image.
   ```bash
   python create_image_paths.py
   ```

2. **Filter Unprocessed Images**:
   - If you need to resume processing or identify images that haven’t been segmented, run `filter_unprocessed_images.py`. This script checks `segmentations_totalsegmentator` for completed segmentations and generates `image_paths_filtered.txt` with only the unprocessed images.
   ```bash
   python filter_unprocessed_images.py
   ```

3. **Split Paths into Batches**:
   - Use `split_paths_into_batches.py` to divide the image paths into manageable batches for parallel processing.
   ```bash
   python split_paths_into_batches.py
   ```

### Step 2: Run Batch Segmentation

#### Option A: Multi-Machine Batch Processing

If your cluster setup supports mounting on multiple machines, you can use `run_totalsegmentator_batch.sh` to submit batch jobs on multiple GPU nodes.

```bash
sbatch run_totalsegmentator_batch.sh
```

#### Option B: Single-Machine Processing

If multi-machine mounting is problematic as it was for me, the pipeline can be run on a single machine using an interactive session. This may take approximately **3-4 days** for a complete run with 1600 CT images on an A100 GPU.

1. **Start an Interactive GPU Session**:
   ```bash
   srun -p gpu --gres=gpu:a100:1 --pty bash
   ```

2. **Run the Pipeline**:
   ```bash
   python totalsegmentator_batchimages.py image_paths.txt
   ```

---

## Output Structure

After segmentation, the output for each image is stored in `IRE-DATA/CT/segmentations_totalsegmentator`. Each input image has a dedicated folder within this directory, and each organ’s segmentation is saved as an `.mha.gz` file.

**Output Naming Convention**:
```
<input_image_name>_totalseg-<organ>.mha.gz
```
For example:
```
sub001_pos-supine_scan-1_conv-sitk_totalseg-liver.mha.gz
sub001_pos-supine_scan-1_conv-sitk_totalseg-heart.mha.gz
```

---

## Script Details

- **`create_image_paths.py`**: Generates `image_paths.txt` containing paths to all input images.
- **`split_paths_into_batches.py`**: Divides `image_paths.txt` into batch files for parallel processing.
- **`filter_unprocessed_images.py`**: Creates `image_paths_filtered.txt` with paths of images that haven’t been processed.
- **`totalsegmentator_batchimages.py`**: Processes each batch by calling `totalsegmentator_oneimage.py` for each image in parallel.
- **`totalsegmentator_oneimage.py`**: Handles each image’s segmentation by:
  - Decompressing `.mha.gz` files.
  - Running TotalSegmentator.
  - Compressing segmented output files to `.mha.gz` format.

---

## Questions?

Contact Viktor on Slack or at *smp884@alumni.ku.dk* or *vikkimar03@gmail.com*.

---
